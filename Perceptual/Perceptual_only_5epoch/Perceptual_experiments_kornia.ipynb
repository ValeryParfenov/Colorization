{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4Evsn16KiuG",
        "outputId": "3f544ed8-6e7f-42b1-ed0c-c91846c7c21b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWw9CTKau9Om",
        "outputId": "46e70f3d-682a-497f-b190-5ff16250c8fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kornia in /usr/local/lib/python3.10/dist-packages (0.7.3)\n",
            "Requirement already satisfied: kornia-rs>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from kornia) (0.1.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia) (24.1)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from kornia) (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.1->kornia) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.1->kornia) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install kornia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMrGRTi2Sndn",
        "outputId": "fdcb894f-70ce-4204-9990-ae5272d4d83c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "import kornia.color\n",
        "from torchvision import transforms, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import ImageCms\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MSEGyqrzSKOq"
      },
      "outputs": [],
      "source": [
        "# fix random seed\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Bh0CjmpiqPut"
      },
      "outputs": [],
      "source": [
        "class config:\n",
        "  batch_size = 32\n",
        "  criterion = nn.MSELoss()\n",
        "  num_epochs = 5\n",
        "  gradient_accumulation_steps = 2\n",
        "  DataFilter_constant = 7\n",
        "  perceptual_layers = range(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGOFUgvBTccW"
      },
      "source": [
        "Load data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "R0NLc7_iTbDD"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/drive/MyDrive/datasets/archive.zip -d datasetn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9AaOvwvhVgi2"
      },
      "outputs": [],
      "source": [
        "# dataset modes\n",
        "DATA_MODES = ['train', 'val', 'test']\n",
        "# all images will be scaled to the size of 224x224 px\n",
        "RESCALE_SIZE = 224\n",
        "# device setting\n",
        "DEVICE = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "17n3vFhtYbdJ"
      },
      "outputs": [],
      "source": [
        "ab1 = torch.tensor(np.load('/content/datasetn/ab/ab/ab1.npy'))\n",
        "ab2 = torch.tensor(np.load('/content/datasetn/ab/ab/ab2.npy'))\n",
        "ab3 = torch.tensor(np.load('/content/datasetn/ab/ab/ab3.npy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWm-AnV6nc52"
      },
      "outputs": [],
      "source": [
        "ab = torch.cat((ab1, ab2,ab3))\n",
        "del(ab1, ab2, ab3)\n",
        "L = torch.tensor(np.load('/content/datasetn/l/gray_scale.npy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHnIuV-mneOT"
      },
      "outputs": [],
      "source": [
        "def DataFilter(X,Y):\n",
        "  good_id = []\n",
        "  for i in tqdm(range(Y.shape[0])):\n",
        "    if torch.std((Y[i].to(dtype=torch.float32)-128)) > config.DataFilter_constant:\n",
        "      good_id.append(i)\n",
        "  X = X[good_id]\n",
        "  Y = Y[good_id]\n",
        "  print(len(good_id))\n",
        "  return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouhRnrYpniRW"
      },
      "outputs": [],
      "source": [
        "L, ab = DataFilter(L, ab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OsLiCuWnzJc"
      },
      "outputs": [],
      "source": [
        "train_X = L[:(L.shape[0]-300)]\n",
        "train_Y = ab[:(L.shape[0]-300)]\n",
        "test_X = L[(L.shape[0]-300):]\n",
        "test_Y = ab[(L.shape[0]-300):]\n",
        "del(L, ab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_65r-LDbxTA"
      },
      "source": [
        "#Make statistics to normalize data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bEBTDWRbV2Vu"
      },
      "outputs": [],
      "source": [
        "train_Xf = train_X.to(dtype = torch.float32)\n",
        "E_X = torch.mean(train_Xf)\n",
        "D_X = torch.std(train_Xf)\n",
        "del(train_Xf)\n",
        "train_Yf = train_Y.to(dtype = torch.float32)\n",
        "E_Y = torch.mean(train_Yf)\n",
        "D_Y = torch.std(train_Yf)\n",
        "del(train_Yf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbuSqodCGRDu"
      },
      "outputs": [],
      "source": [
        "print(D_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj8Ir_pPn60s"
      },
      "source": [
        "# Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_evQKWKvcr9N"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self,X,Y,E_X,D_X,E_Y,D_Y):\n",
        "    self.X = X.unsqueeze(1)\n",
        "    self.Y = Y.transpose(2,3).transpose(1,2)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return ((self.X[index]).to(dtype = torch.float32) - E_X)/D_X, ((self.Y[index]).to(dtype = torch.float32) - E_Y)/D_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IT3AGGRfpXJn"
      },
      "outputs": [],
      "source": [
        "train_dataset = MyDataset(train_X, train_Y,E_X,D_X,E_Y,D_Y)\n",
        "test_dataset = MyDataset(test_X, test_Y,E_X,D_X,E_Y,D_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsjxOidxpniU"
      },
      "outputs": [],
      "source": [
        "train_dataset.X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23xlbQP6pp7C"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNELJ1Q1qlxt"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIjAmiiNqj81"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "  def __init__(self, LayersDepth = [16,32,64,128,256],drop_out_p = 0):\n",
        "    super().__init__()\n",
        "    self.down1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = 1, out_channels = LayersDepth[0], kernel_size=(3,3), padding=1,stride=2),\n",
        "        nn.BatchNorm2d(num_features=LayersDepth[0]),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p),\n",
        "\n",
        "        nn.Conv2d(in_channels = LayersDepth[0], out_channels = LayersDepth[0], kernel_size=(3,3), padding=1,stride=1),\n",
        "        nn.BatchNorm2d(num_features=LayersDepth[0]),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p),\n",
        "\n",
        "        nn.Conv2d(in_channels = LayersDepth[0], out_channels = LayersDepth[0], kernel_size=(3,3), padding=1,stride=1),\n",
        "        nn.BatchNorm2d(num_features=LayersDepth[0]),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p)\n",
        "    )\n",
        "    self.down2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = LayersDepth[0], out_channels = LayersDepth[1], kernel_size=(3,3), padding=1,stride=2),\n",
        "        nn.BatchNorm2d(num_features=LayersDepth[1]),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p),\n",
        "\n",
        "        nn.Conv2d(in_channels = LayersDepth[1], out_channels = LayersDepth[1], kernel_size=(3,3), padding=1,stride=1),\n",
        "        nn.BatchNorm2d(num_features=LayersDepth[1]),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p),\n",
        "\n",
        "        nn.Conv2d(in_channels = LayersDepth[1], out_channels = LayersDepth[1], kernel_size=(3,3), padding=1,stride=1),\n",
        "        nn.BatchNorm2d(num_features=LayersDepth[1]),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p)\n",
        "    )\n",
        "    self.down3 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = LayersDepth[1], out_channels = LayersDepth[2], kernel_size=(3,3), padding=1,stride=2),\n",
        "        nn.BatchNorm2d(num_features=LayersDepth[2]),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p),\n",
        "\n",
        "        nn.Conv2d(in_channels = LayersDepth[2], out_channels = LayersDepth[2], kernel_size=(3,3), padding=1,stride=1),\n",
        "        nn.BatchNorm2d(num_features=LayersDepth[2]),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p),\n",
        "\n",
        "        nn.Conv2d(in_channels = LayersDepth[2], out_channels = LayersDepth[2], kernel_size=(3,3), padding=1,stride=1),\n",
        "        nn.BatchNorm2d(num_features=LayersDepth[2]),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p)\n",
        "    )\n",
        "    self.down4 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = LayersDepth[2], out_channels = LayersDepth[3], kernel_size=(3,3), padding=1,stride=2),\n",
        "        nn.BatchNorm2d(num_features=LayersDepth[3]),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p),\n",
        "\n",
        "        nn.Conv2d(in_channels = LayersDepth[3], out_channels = LayersDepth[3], kernel_size=(3,3), padding=1,stride=1),\n",
        "        nn.BatchNorm2d(num_features=LayersDepth[3]),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p),\n",
        "\n",
        "        nn.Conv2d(in_channels = LayersDepth[3], out_channels = LayersDepth[3], kernel_size=(3,3), padding=1,stride=1),\n",
        "        nn.BatchNorm2d(num_features=LayersDepth[3]),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p)\n",
        "    )\n",
        "    #self.down5 = nn.Sequential(\n",
        "    #    nn.Conv2d(in_channels = LayersDepth[3], out_channels = LayersDepth[4], kernel_size=(3,3), padding=1,stride=2),\n",
        "    #    nn.BatchNorm2d(num_features=LayersDepth[4]),\n",
        "    #    nn.LeakyReLU(),\n",
        "    #    nn.Dropout2d(p = 0.1)\n",
        "    #)\n",
        "\n",
        "    #self.up1 = nn.Sequential(\n",
        "    #    nn.ConvTranspose2d(in_channels=LayersDepth[4],out_channels=LayersDepth[4],kernel_size=(2,2),stride = 2),\n",
        "    #    nn.BatchNorm2d(num_features=LayersDepth[4]),\n",
        "    #    nn.LeakyReLU(),\n",
        "    #    nn.Dropout2d(p = 0.1)\n",
        "    #)\n",
        "    self.up2 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels=LayersDepth[3],out_channels=LayersDepth[3],kernel_size=(2,2),stride = 2),\n",
        "        nn.BatchNorm2d(num_features=LayersDepth[3]),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p),\n",
        "\n",
        "        nn.Conv2d(in_channels = LayersDepth[3], out_channels = LayersDepth[3], kernel_size=(3,3), padding=1,stride=1),\n",
        "        nn.BatchNorm2d(num_features=LayersDepth[3]),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p),\n",
        "\n",
        "        nn.Conv2d(in_channels = LayersDepth[3], out_channels = LayersDepth[3], kernel_size=(3,3), padding=1,stride=1),\n",
        "        nn.BatchNorm2d(num_features=LayersDepth[3]),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p)\n",
        "    )\n",
        "\n",
        "    up3_depth_in = (LayersDepth[3]+LayersDepth[2])\n",
        "    self.up3 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels=up3_depth_in,out_channels = int(up3_depth_in/2),kernel_size=(2,2),stride = 2),\n",
        "        nn.BatchNorm2d(num_features = int(up3_depth_in/2)),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p),\n",
        "\n",
        "        nn.Conv2d(in_channels = int(up3_depth_in/2), out_channels = int(up3_depth_in/2), kernel_size=(3,3), padding=1,stride=1),\n",
        "        nn.BatchNorm2d(num_features=int(up3_depth_in/2)),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p),\n",
        "\n",
        "        nn.Conv2d(in_channels = int(up3_depth_in/2), out_channels = int(up3_depth_in/2), kernel_size=(3,3), padding=1,stride=1),\n",
        "        nn.BatchNorm2d(num_features=int(up3_depth_in/2)),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p)\n",
        "    )\n",
        "    up4_depth_in = int(up3_depth_in/2) + LayersDepth[1]\n",
        "    self.up4 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels = up4_depth_in,out_channels = int(up4_depth_in/2),kernel_size=(2,2),stride = 2),\n",
        "        nn.BatchNorm2d(num_features = int(up4_depth_in/2)),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p),\n",
        "\n",
        "        nn.Conv2d(in_channels = int(up4_depth_in/2), out_channels = int(up4_depth_in/2), kernel_size=(3,3), padding=1,stride=1),\n",
        "        nn.BatchNorm2d(num_features=int(up4_depth_in/2)),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p),\n",
        "\n",
        "        nn.Conv2d(in_channels = int(up4_depth_in/2), out_channels = int(up4_depth_in/2), kernel_size=(3,3), padding=1,stride=1),\n",
        "        nn.BatchNorm2d(num_features=int(up4_depth_in/2)),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p)\n",
        "    )\n",
        "    up5_depth_in = int(up4_depth_in/2) + LayersDepth[0]\n",
        "    self.up5 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels = up5_depth_in,out_channels = int(up5_depth_in/2),kernel_size=(2,2),stride = 2),\n",
        "        nn.BatchNorm2d(num_features = int(up5_depth_in/2)),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p),\n",
        "\n",
        "        nn.Conv2d(in_channels = int(up5_depth_in/2), out_channels = int(up5_depth_in/2), kernel_size=(3,3), padding=1,stride=1),\n",
        "        nn.BatchNorm2d(num_features=int(up5_depth_in/2)),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p),\n",
        "\n",
        "        nn.Conv2d(in_channels = int(up5_depth_in/2), out_channels = int(up5_depth_in/2), kernel_size=(3,3), padding=1,stride=1),\n",
        "        nn.BatchNorm2d(num_features=int(up5_depth_in/2)),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout2d(p = drop_out_p)\n",
        "    )\n",
        "    self.final_layer = nn.Conv2d(in_channels = int(up5_depth_in/2)+1, out_channels = 2, kernel_size=(1,1))\n",
        "\n",
        "\n",
        "  def forward(self, Input):\n",
        "    x1 = self.down1(Input)\n",
        "    x2 = self.down2(x1)\n",
        "    x3 = self.down3(x2)\n",
        "    x = self.down4(x3)\n",
        "    #x = self.down5(x4)\n",
        "    #x = self.up1(x)\n",
        "    x = self.up2(x)\n",
        "    x = self.up3(torch.cat((x,x3),1))\n",
        "    x = self.up4(torch.cat((x,x2),1))\n",
        "    x = self.up5(torch.cat((x,x1),1))\n",
        "    x = self.final_layer(torch.cat((x,Input),1))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8knrEP6vltt"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YNZmYpHovpYg"
      },
      "outputs": [],
      "source": [
        "model = UNet()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm2qnlLRwkVe"
      },
      "source": [
        "#Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBcg64FhvuGh"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AcH6Spjw4_j"
      },
      "source": [
        "#Perceptual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JiawmAWw8sb"
      },
      "outputs": [],
      "source": [
        "loss_model = models.vgg16(weights='IMAGENET1K_V1').features.to(device)\n",
        "\n",
        "def extract_features(model, x, layers):\n",
        "    features = torch.tensor([],device = device)\n",
        "    for index, layer in enumerate(model):\n",
        "        x = layer(x)\n",
        "        if index in layers:\n",
        "            features = torch.cat((features,x.reshape(-1)))\n",
        "    return features\n",
        "\n",
        "def Prepare_img_for_perception(L,ab,E_X,D_X,E_Y,D_Y):\n",
        "    #denormalizing data\n",
        "    L = L * D_X + E_X\n",
        "    ab = ab * D_Y + E_Y\n",
        "    L = L / 2.56\n",
        "    ab = ab - 128\n",
        "    #transform for pretrained loss_model\n",
        "    perseptual_transform = transforms.Compose([\n",
        "      transforms.Pad(2),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    #making RGB from Lab\n",
        "    image_lab = torch.cat((L,ab), dim = 1)\n",
        "    #image_lab = image_lab.to(dtype = torch.int).to(dtype = torch.float32)\n",
        "    #print(image_lab[:,0,:,:].max(),image_lab[:,0,:,:].min(),image_lab[:,1,:,:].max(),image_lab[:,1,:,:].min(),image_lab[:,2,:,:].max(),image_lab[:,2,:,:].min())\n",
        "    image_rgb = kornia.color.lab_to_rgb(image_lab)\n",
        "    #_______________________\n",
        "    # For testing:\n",
        "    #counter = 0\n",
        "    #for im in image_rgb:\n",
        "    #  counter += 1\n",
        "    #  pic = im.transpose(0,2).transpose(0,1)\n",
        "    #  plt.imshow(pic.detach().cpu())\n",
        "    #  plt.savefig(f'testing_im{counter}.pdf')\n",
        "    #_______________________\n",
        "    #return perseptual_transform(torch.tensor(image_rgb, dtype = torch.float32, device = device).transpose(1,3).transpose(2,3))\n",
        "    return perseptual_transform(image_rgb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aps0Ld3w3sK"
      },
      "source": [
        "#Train loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WL_2ko3Pw2tU"
      },
      "outputs": [],
      "source": [
        "def train(model, criterion, optimizer,\n",
        "          train_dataloader, test_dataloader, num_epochs):\n",
        "\n",
        "    train_losses = np.zeros(num_epochs)\n",
        "    test_losses = np.zeros(num_epochs)\n",
        "    best_test_loss = torch.inf\n",
        "    for i_epoch in tqdm(range(num_epochs)):\n",
        "        train_loss = 0\n",
        "        test_loss = 0\n",
        "\n",
        "        # train step\n",
        "        model.train()\n",
        "        counter = 0\n",
        "        for batch in tqdm(train_dataloader):\n",
        "            X = batch[0].to(device = device)\n",
        "            y = batch[1].to(device = device)\n",
        "            #.to(device = device)\n",
        "\n",
        "            # model forward-pass\n",
        "            preds = model(X)\n",
        "            original_perseptence = extract_features(loss_model,\n",
        "                                       Prepare_img_for_perception(X,y,E_X,D_X,E_Y,D_Y),config.perceptual_layers)\n",
        "            preds_perseptence = extract_features(loss_model,\n",
        "                                       Prepare_img_for_perception(X,preds,E_X,D_X,E_Y,D_Y),config.perceptual_layers)\n",
        "\n",
        "            loss = criterion(preds_perseptence, original_perseptence)\n",
        "            loss.backward()\n",
        "            # model backward-pass\n",
        "            if counter == config.gradient_accumulation_steps:\n",
        "              optimizer.step()\n",
        "              optimizer.zero_grad()\n",
        "              counter = 0\n",
        "            counter += 1\n",
        "\n",
        "\n",
        "\n",
        "            # save loss\n",
        "            train_loss += loss.detach().cpu().numpy()\n",
        "\n",
        "        train_loss /= len(train_dataloader)\n",
        "        train_losses[i_epoch] = train_loss\n",
        "\n",
        "        torch.save({\n",
        "                'epoch': i_epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                }, 'last_checkpoint.pth')\n",
        "\n",
        "        # test step\n",
        "        model.eval()\n",
        "        for batch in test_dataloader:\n",
        "            X = batch[0].to(device = device)\n",
        "            y = batch[1].to(device = device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # model forward-pass\n",
        "                preds = model(X)\n",
        "\n",
        "                original_perseptence = extract_features(loss_model,\n",
        "                                       Prepare_img_for_perception(X,y,E_X,D_X,E_Y,D_Y),config.perceptual_layers)\n",
        "                preds_perseptence = extract_features(loss_model,\n",
        "                                       Prepare_img_for_perception(X,preds,E_X,D_X,E_Y,D_Y),config.perceptual_layers)\n",
        "\n",
        "                loss = criterion(preds_perseptence, original_perseptence)\n",
        "\n",
        "                # save loss\n",
        "                test_loss += loss.detach().cpu().numpy()\n",
        "\n",
        "        test_loss /= len(test_dataloader)\n",
        "\n",
        "        test_losses[i_epoch] = test_loss\n",
        "\n",
        "        if test_loss < best_test_loss:\n",
        "                best_test_loss = test_loss\n",
        "\n",
        "                torch.save({\n",
        "                            'epoch': i_epoch,\n",
        "                            'model_state_dict': model.state_dict(),\n",
        "                            'optimizer_state_dict': optimizer.state_dict(),\n",
        "                            }, 'best_checkpoint.pth')\n",
        "\n",
        "    return train_losses, test_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoKZEbfjywjO"
      },
      "source": [
        "#Model train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-jPu-eqx5IK"
      },
      "outputs": [],
      "source": [
        "model_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of trainable parameters: {model_total_params}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZlT3vvvy5D7"
      },
      "outputs": [],
      "source": [
        "train_losses, \\\n",
        "    test_losses = train(model, criterion=config.criterion,\n",
        "                              optimizer=optimizer,\n",
        "                              train_dataloader=train_dataloader,\n",
        "                              test_dataloader=test_dataloader,\n",
        "                              num_epochs=config.num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I1MN4tBzZua"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(config.num_epochs),test_losses, label = '$test\\_loss(N_{epoch})$')\n",
        "plt.plot(np.arange(config.num_epochs),train_losses, label = '$train\\_loss(N_{epoch})$')\n",
        "#plt.yscale('log')\n",
        "plt.legend(loc = 'best')\n",
        "plt.savefig('loss.pdf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hScaLT82b9d"
      },
      "source": [
        "#Trying to interpret results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlwapKfbLWCW"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "def get_LAB(image_l, image_ab):\n",
        "    image_lab = np.zeros((224, 224, 3))\n",
        "    image_lab[:, :, 0] = image_l\n",
        "    image_lab[:, :, 1:] = image_ab\n",
        "    image_lab = image_lab.astype(\"uint8\")\n",
        "    image_rgb = cv2.cvtColor(image_lab, cv2.COLOR_LAB2RGB)\n",
        "    image_rgb = Image.fromarray(image_rgb)\n",
        "    return image_rgb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQOzR5xa0EhX"
      },
      "source": [
        "# Let's look on dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtGyhNIYtcPq"
      },
      "outputs": [],
      "source": [
        "#fig, ax = plt.subplots(nrows=150, ncols=1,figsize=(8,400), \\\n",
        "#                       sharey=True, sharex=True)\n",
        "#for k in range(150):\n",
        "#  ax[k].imshow(get_LAB(train_dataset.X[77+k].numpy(),train_Y[k+77].numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjWArpkS1IY7"
      },
      "source": [
        "# And results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DexsJVA9I909"
      },
      "outputs": [],
      "source": [
        "  fig, ax = plt.subplots(nrows=40, ncols=3,figsize=(8,110), \\\n",
        "                        sharey=True, sharex=True)\n",
        "\n",
        "\n",
        "\n",
        "  for k in range(40):\n",
        "    ax[k,2].imshow(test_dataset.X[77+k,0,:,:], cmap='gray', vmin=0, vmax=256)\n",
        "    ax[k,1].imshow(get_LAB((test_dataset.X[k+77]).numpy(),((D_Y.to(device = 'cuda')*model(torch.unsqueeze((test_dataset.X[k+77]-E_X)/D_X,0).to(device = 'cuda',\\\n",
        "            dtype=torch.float32))+E_Y.to(device = 'cuda')).squeeze().transpose(0,2).transpose(0,1).to(device = 'cpu').detach()).numpy()))\n",
        "    ax[k,0].imshow(get_LAB(test_dataset.X[77+k].numpy(),test_Y[k+77].numpy()))\n",
        "\n",
        "  fig.savefig('results.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icthjJhVeqkk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
